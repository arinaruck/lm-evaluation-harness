{
  "results": [
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "bleu": 1.4121344097815682,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "bleu_stderr": 0.12610953207838813
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_precision": 0.042164919791764593,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_precision_stderr": 0.0039038971714412045
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_recall": 0.3826367647015743,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_recall_stderr": 0.014408952730621169
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_fmeasure": 0.06991910003199,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_fmeasure_stderr": 0.003057485967820925
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_precision": 0.01870254975641194,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_precision_stderr": 0.002254347166143275
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_recall": 0.17615573793748596,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_recall_stderr": 0.013661961177700889
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_fmeasure": 0.031018955172947678,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_fmeasure_stderr": 0.002598286498336011
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_precision": 0.03942372766134062,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_precision_stderr": 0.0028990459265606154
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_recall": 0.3671795543318999,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_recall_stderr": 0.014301916231823962
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_fmeasure": 0.0667996380039431,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_fmeasure_stderr": 0.0029664979432005223
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_precision": 0.037702536413759126,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_precision_stderr": 0.003894065332848575
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_recall": 0.3375510316547167,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_recall_stderr": 0.013842719474644353
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_fmeasure": 0.06185027254860532,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_fmeasure_stderr": 0.002961028362791267
    }
  ],
  "versions": {
    "mrpc+generate_sentence": 0
  },
  "table_results": {
    "mrpc+generate_sentence": {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "bleu": 1.4121344097815682,
      "bleu_stderr": 0.12610953207838813,
      "rouge1_precision": 0.042164919791764593,
      "rouge1_precision_stderr": 0.0039038971714412045,
      "rouge1_recall": 0.3826367647015743,
      "rouge1_recall_stderr": 0.014408952730621169,
      "rouge1_fmeasure": 0.06991910003199,
      "rouge1_fmeasure_stderr": 0.003057485967820925,
      "rouge2_precision": 0.01870254975641194,
      "rouge2_precision_stderr": 0.002254347166143275,
      "rouge2_recall": 0.17615573793748596,
      "rouge2_recall_stderr": 0.013661961177700889,
      "rouge2_fmeasure": 0.031018955172947678,
      "rouge2_fmeasure_stderr": 0.002598286498336011,
      "rougeL_precision": 0.03942372766134062,
      "rougeL_precision_stderr": 0.0028990459265606154,
      "rougeL_recall": 0.3671795543318999,
      "rougeL_recall_stderr": 0.014301916231823962,
      "rougeL_fmeasure": 0.0667996380039431,
      "rougeL_fmeasure_stderr": 0.0029664979432005223,
      "rougeLsum_precision": 0.037702536413759126,
      "rougeLsum_precision_stderr": 0.003894065332848575,
      "rougeLsum_recall": 0.3375510316547167,
      "rougeLsum_recall_stderr": 0.013842719474644353,
      "rougeLsum_fmeasure": 0.06185027254860532,
      "rougeLsum_fmeasure_stderr": 0.002961028362791267
    }
  }
}