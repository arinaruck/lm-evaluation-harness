{
  "results": [
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "bleu": 1.42818272331511,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "bleu_stderr": 0.12603334154987372
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_precision": 0.042354506662166405,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_precision_stderr": 0.0039020079186275675
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_recall": 0.38519692855206067,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_recall_stderr": 0.01443746469271423
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_fmeasure": 0.07027213710318134,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_fmeasure_stderr": 0.003052705261342853
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_precision": 0.0188542631697741,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_precision_stderr": 0.002254924601099527
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_recall": 0.17836141756252044,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_recall_stderr": 0.013737500921575708
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_fmeasure": 0.03130285453062539,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_fmeasure_stderr": 0.002601602808617839
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_precision": 0.039613314531742425,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_precision_stderr": 0.002897146658727545
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_recall": 0.3697397181823863,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_recall_stderr": 0.014340570896611822
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_fmeasure": 0.06715267507513442,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_fmeasure_stderr": 0.0029629076825308546
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_precision": 0.03789212328416094,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_precision_stderr": 0.003892953106084693
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_recall": 0.3401111955052032,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_recall_stderr": 0.013902293318252814
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_fmeasure": 0.062203309619796636,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_fmeasure_stderr": 0.0029595559506915016
    }
  ],
  "versions": {
    "mrpc+generate_sentence": 0
  },
  "table_results": {
    "mrpc+generate_sentence": {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "bleu": 1.42818272331511,
      "bleu_stderr": 0.12603334154987372,
      "rouge1_precision": 0.042354506662166405,
      "rouge1_precision_stderr": 0.0039020079186275675,
      "rouge1_recall": 0.38519692855206067,
      "rouge1_recall_stderr": 0.01443746469271423,
      "rouge1_fmeasure": 0.07027213710318134,
      "rouge1_fmeasure_stderr": 0.003052705261342853,
      "rouge2_precision": 0.0188542631697741,
      "rouge2_precision_stderr": 0.002254924601099527,
      "rouge2_recall": 0.17836141756252044,
      "rouge2_recall_stderr": 0.013737500921575708,
      "rouge2_fmeasure": 0.03130285453062539,
      "rouge2_fmeasure_stderr": 0.002601602808617839,
      "rougeL_precision": 0.039613314531742425,
      "rougeL_precision_stderr": 0.002897146658727545,
      "rougeL_recall": 0.3697397181823863,
      "rougeL_recall_stderr": 0.014340570896611822,
      "rougeL_fmeasure": 0.06715267507513442,
      "rougeL_fmeasure_stderr": 0.0029629076825308546,
      "rougeLsum_precision": 0.03789212328416094,
      "rougeLsum_precision_stderr": 0.003892953106084693,
      "rougeLsum_recall": 0.3401111955052032,
      "rougeLsum_recall_stderr": 0.013902293318252814,
      "rougeLsum_fmeasure": 0.062203309619796636,
      "rougeLsum_fmeasure_stderr": 0.0029595559506915016
    }
  }
}