{
  "results": [
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "bleu": 3.9224600125762854,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "bleu_stderr": 0.2843055100568434
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_precision": 0.11079626853623403,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_precision_stderr": 0.01308524039798886
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_recall": 0.2813192155073059,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_recall_stderr": 0.02134414467138522
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_fmeasure": 0.12536262153680974,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_fmeasure_stderr": 0.012239283917975612
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_precision": 0.08066885617435535,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_precision_stderr": 0.010632348684832047
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_recall": 0.20136883373795345,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_recall_stderr": 0.01655295122019616
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_fmeasure": 0.08883685071485241,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_fmeasure_stderr": 0.009439406200335478
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_precision": 0.10736668867176259,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_precision_stderr": 0.01262040329300138
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_recall": 0.2766841274264142,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_recall_stderr": 0.02105068986981356
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_fmeasure": 0.12183279814332051,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_fmeasure_stderr": 0.011774738621211948
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_precision": 0.10592492805828398,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_precision_stderr": 0.012803234405737931
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_recall": 0.2623362744509227,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_recall_stderr": 0.020116852414414365
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_fmeasure": 0.1190776110374979,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_fmeasure_stderr": 0.011927911268679718
    }
  ],
  "versions": {
    "mrpc+generate_sentence": 0
  },
  "table_results": {
    "mrpc+generate_sentence": {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "bleu": 3.9224600125762854,
      "bleu_stderr": 0.2843055100568434,
      "rouge1_precision": 0.11079626853623403,
      "rouge1_precision_stderr": 0.01308524039798886,
      "rouge1_recall": 0.2813192155073059,
      "rouge1_recall_stderr": 0.02134414467138522,
      "rouge1_fmeasure": 0.12536262153680974,
      "rouge1_fmeasure_stderr": 0.012239283917975612,
      "rouge2_precision": 0.08066885617435535,
      "rouge2_precision_stderr": 0.010632348684832047,
      "rouge2_recall": 0.20136883373795345,
      "rouge2_recall_stderr": 0.01655295122019616,
      "rouge2_fmeasure": 0.08883685071485241,
      "rouge2_fmeasure_stderr": 0.009439406200335478,
      "rougeL_precision": 0.10736668867176259,
      "rougeL_precision_stderr": 0.01262040329300138,
      "rougeL_recall": 0.2766841274264142,
      "rougeL_recall_stderr": 0.02105068986981356,
      "rougeL_fmeasure": 0.12183279814332051,
      "rougeL_fmeasure_stderr": 0.011774738621211948,
      "rougeLsum_precision": 0.10592492805828398,
      "rougeLsum_precision_stderr": 0.012803234405737931,
      "rougeLsum_recall": 0.2623362744509227,
      "rougeLsum_recall_stderr": 0.020116852414414365,
      "rougeLsum_fmeasure": 0.1190776110374979,
      "rougeLsum_fmeasure_stderr": 0.011927911268679718
    }
  }
}