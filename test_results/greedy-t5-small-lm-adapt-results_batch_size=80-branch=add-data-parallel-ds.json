{
  "results": [
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "bleu": 0.0,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "bleu_stderr": 0.0
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_precision": 0.10931899641577057,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_precision_stderr": 0.015198238204246622
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_recall": 0.01080946423627059,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_recall_stderr": 0.0013817101706401283
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge1_fmeasure": 0.019129543325106288,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge1_fmeasure_stderr": 0.0024219300008897254
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_precision": 0.0,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_precision_stderr": 0.0
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_recall": 0.0,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_recall_stderr": 0.0
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rouge2_fmeasure": 0.0,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rouge2_fmeasure_stderr": 0.0
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_precision": 0.10931899641577057,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_precision_stderr": 0.015198238204246622
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_recall": 0.01080946423627059,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_recall_stderr": 0.0013817101706401283
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeL_fmeasure": 0.019129543325106288,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeL_fmeasure_stderr": 0.0024219300008897254
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_precision": 0.10931899641577057,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_precision_stderr": 0.015198238204246622
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_recall": 0.01080946423627059,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_recall_stderr": 0.0013817101706401283
    },
    {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "rougeLsum_fmeasure": 0.019129543325106288,
      "fixed_answer_choice_list": null,
      "dataset_path": "glue",
      "dataset_name": "mrpc",
      "subset": null,
      "prompt_id": "d830d7a5-abc0-4275-ac62-974e0088876f",
      "prompt_jinja": "{% if label == 1 %}\nGenerate a sentence that means the same thing as this one: {{sentence1}}\n|||\n{{sentence2}}\n{% endif %}",
      "prompt_original_task": false,
      "comment": "",
      "rougeLsum_fmeasure_stderr": 0.0024219300008897254
    }
  ],
  "versions": {
    "mrpc+generate_sentence": 0
  },
  "table_results": {
    "mrpc+generate_sentence": {
      "task_name": "mrpc",
      "prompt_name": "generate_sentence",
      "bleu": 0.0,
      "bleu_stderr": 0.0,
      "rouge1_precision": 0.10931899641577057,
      "rouge1_precision_stderr": 0.015198238204246622,
      "rouge1_recall": 0.01080946423627059,
      "rouge1_recall_stderr": 0.0013817101706401283,
      "rouge1_fmeasure": 0.019129543325106288,
      "rouge1_fmeasure_stderr": 0.0024219300008897254,
      "rouge2_precision": 0.0,
      "rouge2_precision_stderr": 0.0,
      "rouge2_recall": 0.0,
      "rouge2_recall_stderr": 0.0,
      "rouge2_fmeasure": 0.0,
      "rouge2_fmeasure_stderr": 0.0,
      "rougeL_precision": 0.10931899641577057,
      "rougeL_precision_stderr": 0.015198238204246622,
      "rougeL_recall": 0.01080946423627059,
      "rougeL_recall_stderr": 0.0013817101706401283,
      "rougeL_fmeasure": 0.019129543325106288,
      "rougeL_fmeasure_stderr": 0.0024219300008897254,
      "rougeLsum_precision": 0.10931899641577057,
      "rougeLsum_precision_stderr": 0.015198238204246622,
      "rougeLsum_recall": 0.01080946423627059,
      "rougeLsum_recall_stderr": 0.0013817101706401283,
      "rougeLsum_fmeasure": 0.019129543325106288,
      "rougeLsum_fmeasure_stderr": 0.0024219300008897254
    }
  }
}